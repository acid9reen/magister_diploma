\chapter{Программная реализация}

Экспериментальным путем было решено разбить решение задачи детекции активаций
на две части. Первая часть --- поиск области активации с помощью
сегментирующей нейронной сети, вторая --- поиск прямыми методами точки
интереса.

Для реализации использовался язык программирования Python, а так же такие библиотеки как:

\begin{itemize}
	\item PyTorch: построение модели, обучение и предсказание
	\item NumPy: чтение/запись и предобработка записей сигналов и разметки
	\item SciPy: предобработка записей сигналов
	\item mlflow: хранение информации об экспериментах и отслеживание метрик
	\item ONNX: предсказание
	\item DearPyGui: графический интерфейс для некоторых вспомогательных программ
\end{itemize}

\noindent Исходный код с реализацией функционала описанного в этой главе содержится
в \cite{heartbeat-detector-source,egm-analyzer-source}.

\section{Модель}

В качестве нейронной сети для сегментации сигнала была выбрана модель типа
"UNet". Выбор пал на нее, так как уже были работы, где она себя хорошо
зарекомендовала в схожей задаче \cite{victor}. В целом, это достаточно похожая
на оригинал одномерная версия модели. Однако не обошлось и без модификаций:

\begin{enumerate}

	\item Паддинг: для сохранения размера вектора при свертках используется
	паддинг с зеркальным заполнением. Так же это позволяет получить равный по
	размеру входу выход.

	\item Upsample: вместо обратных сверток на этапе восстановления
	используется upsample. Это необучаемая часть нейросети, поэтому обучение и
	предсказание занимает заметно меньше времени.

\end{enumerate}

Сама модель состоит только из сверток, pooling слоев и слоев upsample, то есть
не включает в себя полносвязные слои. Можно выделить две части: ``спуск'' и
``подъем''. Каждый слой спуска состоит из двух последовательных сверток и слоя
max pool. Слой же подъема почти в точности повторяет спуск с тем отличием, что
выполняет обратную операцию, в связи с чем вместо max pool использует upsample.
Так же в архитектуре присутствуют остаточные связи, они соединяют
соответствующие части спуска и подъема посредством конкатенации тензоров.
Наглядно нейросеть изображена на рис. \ref{fig:unet}.

\begin{figure}[!htb]
	\centering
	\caption{Архитектура нейронной сети UNet}
	\includegraphics[width=\textwidth]{unet.png}
	\label{fig:unet}
\end{figure}

Так как записи сигналов могут иметь разное количество каналов, было решено, что
нейросеть будет сегментировать по одному каналу за раз вместо нескольких или
даже всех. Далее исходя из компромисса между доступными ресурсами и желанием
подавать на вход нейросети как можно больший сигнал, было решено остановится на
размере входа в 10000 сэмплов, что в нашем случае (при дискретизации в 5 кГц)
эквивалентно 2 секундам. Полный описание модели приведено в приложении (см.
\hyperref[lst:unet]{Приложение})

\subsection{Обучение}

Обучение нейронной сети производилось на компьютере со следующими характеристиками:

\begin{enumerate}
	\item GPU: Nvidia GeForce RTX3070 (8Гб видеопамяти)
	\item RAM: 32Гб
	\item CPU: Intel Core i5 (6 ядер x 2.5 Ггц)
\end{enumerate}

В качестве метода оптимизации использовался adam (как один из самых продвинутых
методов стохастического градиентного спуска \cite{adam}) в паре с milestone
планировщиком для динамического контроля learning rate во время обучения.

\subsubsection{Отслеживание экспериментов и метрик}

Благодаря тому, что в стеке используемых технологий есть язык программирования
Python, открывается возможность использования разнообразных библиотек для
удобства отслеживания экспериментов. В данном случае была выбрана библиотека
mlflow. Использовалась она для хранения информации о параметрах экспериментов,
таких как, например, learning rate, test fold, файл с реализаций нейронной
сети, loss, а так же для отслеживания метрик моделей (см. рис.
\ref{fig:mlflow-metrics}). В качестве такой метрики была loss функция. Она
записывалась на каждом пакете и эпохе.

\begin{figure}[!htb]
	\centering
	\caption{Пример отображения метрик для эксперимента в mlflow}
	\includegraphics[width=\textwidth]{mlflow-metrics.png}
	\label{fig:mlflow-metrics}
\end{figure}

\subsection{Предсказание}
\subsubsection{Предобработка}

При предсказании необходимо привести файл к виду, максимально приближенному к
тому, какой имели записи сигналов, на которых обучалась нейросеть. В связи с
чем в предсказании появляется шаг предобработки, полностью повторяющий
процедуры, которые использовались для генерации датасета, а именно: децимацию,
фильтрацию и масштабирование.

\subsubsection{Применение нейронной сети}

На вход программе может подаваться сигнал произвольной длины с любым
количеством каналов. Из-за этого предсказание построено путем обработки одного
канала за раз. Так же важно отметить, что из-за особенностей архитектуры UNet
на концах предсказания могут появляться нежелательные артефакты. Ввиду этого
вместо обычной последовательной итерации по сигналу (сначала обрабатываем часть
сигнала, равного длине входа, далее следующую и так далее) используется
итерация с пересечением и отбрасыванием частей предсказания с начала и конца. В
экспериментах в качестве предсказания бралось 80\% исходного предсказания (то
есть отбрасывалось 10\% с начала предсказания и 10\% --- с конца).

\section{Постобработка}
Сырой выход модели представляет собой тензор таких же размеров, что и вход,
который содержит вероятности наличия активации в каждой точке входного сигнала.
Однако, для нас интересны конкретные активации. Поэтому после предсказания
моделью строятся отрезки поиска активаций. Эти отрезки представляют собой
последовательные участки сигнала с вероятностями нахождения в них активаций
больше заданного порога.

Активация в данной работе определяется как точка максимального спада сигнала,
то есть, формально говоря, это минимум первой производной от кривой сигнала.
Для поиска этой точки на искомых участках предлагается строить сплайн и
рассчитывать его производную для более точного определения нужной точки
активации. Найденные таким образом точки считаются конечным результатом работы
программы.

\section{Анализ ошибок}

Важную роль в процессе улучшения программы играет анализ ошибок, именно
благодаря ему был улучшен изначальный алгоритм, который по точности был сравним
с исходной разметкой. Для этой возможности была разработана специальная
программа с графическим пользовательским интерфейсом (см. рис.
\ref{fig:error-analyser}). Программа позволяет:

\begin{enumerate}

	\item Просматривать случайные ошибки: С помощью программы можно
	просматривать случайные ошибки, которые допустила модель при обнаружении
	активаций в сигналах ЭГ. Это помогает исследователям лучше понять причины
	ошибок и выявить особенности сигналов, которые могут привести к
	неправильному обнаружению. Ошибка выбирается случайно, так как их общее
	количество может варьироваться от нескольких сотен до тысяч, что не дает
	возможности исследователю ознакомится с ними всеми.

	\item Отображать промежуток активации нейросети: Программа помечает
	промежуток сигнала, в котором модель обнаружила активацию выше заданного
	порога. Это позволяет анализировать, насколько корректно модель определяет
	временные интервалы активности.

	\item Показывать оригинальную разметку: Для сравнения результатов модели с
	истинной разметкой сигналов ЭГ программа отображает оригинальную разметку
	данных, что помогает выявлять различия между предсказаниями модели и
	истинной разметкой.

	\item Определять тип ошибки: Программа классифицирует ошибки модели и
	указывает их тип. Например, это может быть ложное срабатывание (false
	positive), когда модель ошибочно обнаруживает активацию там, где ее нет,
	или пропуск активации (false negative), когда модель не обнаруживает
	наличие активации.

	\item Просматривать смежные каналы: Для более полноценного анализа сигналов
	ЭГ программа позволяет просматривать смежные каналы для учета
	исследователями контекста и особенностей сигнала на других каналах при
	анализе ошибок.

\end{enumerate}


\begin{figure}[!htb]
	\centering
	\caption{Пользовательский интерфейс программы для анализа ошибок предсказания}
	\includegraphics[width=\textwidth]{error-analyzer.png}
	\label{fig:error-analyser}
\end{figure}
